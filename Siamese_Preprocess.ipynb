{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5C0emv2Iia_",
        "outputId": "46323e99-5b41-4a97-abd8-0c5a141271a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2zRuDdUgJIF4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import gzip\n",
        "import csv\n",
        "import json\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import requests\n",
        "import re\n",
        "pd.set_option('display.max_rows', 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siqyURwxIZxq"
      },
      "outputs": [],
      "source": [
        "# only a single epoch of 50 of those datasets was used\n",
        "\n",
        "# load very small subset of csv\n",
        "# need to create nbr of cards in pack x 3 torch.Tensor for each pick (line)\n",
        "# ask how to make model train directly on data instead of creating file for it, for efficiency/storage issues\n",
        "\n",
        "# 0. Create new cols: anchors, positives, negatives\n",
        "# 1. anchors, already created (pool_card), repeated over the number of cards in pack\n",
        "#    just need to create new col and create one-hot tensor of it\n",
        "# 2. positives, already created (pick), similar as for anchors\n",
        "# 3. negatives, representation of each possible WRONG pick\n",
        "# get inspired from their code\n",
        "# ultimately, each pick/line should result into anywhere between 2 and 13 lines (training examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBi5z6ysgfQ4"
      },
      "outputs": [],
      "source": [
        "def create_card_dict(df, pathout):\n",
        "  card_dict = dict()\n",
        "  index = 0\n",
        "  for card in df.columns[df.columns.str.startswith('pack_card')]:\n",
        "    card_dict[card.replace('pack_card_', '')]=index\n",
        "    index+=1\n",
        "  with open(pathout, 'wb') as f:\n",
        "            pickle.dump(card_dict,f)\n",
        "            f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGUeR9PHrvWR"
      },
      "outputs": [],
      "source": [
        "#create_card_dict(df, \"/content/drive/MyDrive/Colab Notebooks/data/card_dict.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tpBqVw6owESf"
      },
      "outputs": [],
      "source": [
        "#loading card_dict\n",
        "card_dict = pickle.load(open(r\"Data\\card_dictDMU.pt\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ni1NMmr0ofkh"
      },
      "outputs": [],
      "source": [
        "#defining data_types per column and load data function\n",
        "COLUMN_REGEXES = {\n",
        "    re.compile(r'user_game_win_rate_bucket'): 'float16',\n",
        "    re.compile(r'user_n_games_bucket'): 'int8',\n",
        "    re.compile(r'draft_id'): 'str',\n",
        "    re.compile(r'draft_time'): 'str',\n",
        "    re.compile(r'expansion'): 'str',\n",
        "    re.compile(r'event_type'): 'str',\n",
        "    re.compile(r'event_match_wins'): 'int8',\n",
        "    re.compile(r'event_match_losses'): 'int8',\n",
        "    re.compile(r'pack_number'): 'int8',\n",
        "    re.compile(r'pick_number'): 'int8',\n",
        "    re.compile(r'pick'): 'str',\n",
        "    re.compile(r'pick_maindeck_rate'): 'float16',\n",
        "    re.compile(r'pick_sideboard_in_rate'): 'float16',\n",
        "\n",
        "    re.compile(r'pool_.*'): 'int8',\n",
        "    re.compile(r'pack_card_.*'): 'int8',\n",
        "}\n",
        "\n",
        "def load_data(filename):\n",
        "    col_names = pd.read_csv(filename, nrows=0).columns\n",
        "    data_types = {}\n",
        "    for c in col_names:\n",
        "        for (r, t) in COLUMN_REGEXES.items():\n",
        "            if r.match(c):\n",
        "                data_types[c] = t\n",
        "    skipcols= ['draft_time',\n",
        "               'event_type',\n",
        "               'expansion',\n",
        "               'event_match_wins',\n",
        "               'event_match_losses',\n",
        "               'user_n_games_bucket',\n",
        "               'user_game_win_rate_bucket',\n",
        "               'pick_maindeck_rate',\n",
        "               'pick_sideboard_in_rate',\n",
        "               'draft_id',\n",
        "               #'pick_number',\n",
        "               #'pack_number',\n",
        "               'rank'\n",
        "                ]\n",
        "    df = pd.read_csv(\n",
        "        filename,\n",
        "        dtype=data_types,\n",
        "        #nrows=100000,\n",
        "        #skiprows=range(1, 5000000),\n",
        "        chunksize=100000,\n",
        "        usecols = lambda x: x not in skipcols\n",
        "        #usecols = ['rank', 'pack_number', 'pick_number']\n",
        "    )\n",
        "      \n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2AwTLADa8jKn"
      },
      "outputs": [],
      "source": [
        "#loading and sorting dataframe\n",
        "data_chunks = []\n",
        "for chunk in load_data(r\"Data\\finaltrain.csv\"):\n",
        "  data_chunks.append(chunk)\n",
        "df = pd.concat(data_chunks, axis=0)\n",
        "pick_col = np.array(df.columns[0])\n",
        "sorted_cols = np.sort(df.columns[1:].tolist())\n",
        "sorted_cols = np.insert(sorted_cols, 0, pick_col, axis=0)\n",
        "df = df.loc[:, sorted_cols]\n",
        "\n",
        "#creating anchor, positive and negative tensor columns\n",
        "anchor_cols = df.columns[df.columns.str.startswith('pool_')]\n",
        "df['anchors'] = df[anchor_cols].apply(lambda x: x.tolist(), axis=1)\n",
        "pack_cols = df.columns[df.columns.str.startswith('pack_card')]\n",
        "df['positives'] = df['pick'].apply(lambda x: str(card_dict[x]))\n",
        "df[\"negatives\"] = df[pack_cols].apply(lambda x: x.tolist(), axis=1)\n",
        "\n",
        "#creating training dataframe (columns = anchors, positives, negatives)\n",
        "df = df[[\"positives\",\"negatives\",\"anchors\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2pWtmxD6v-45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5957238 entries, 0 to 5957237\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Dtype \n",
            "---  ------     ----- \n",
            " 0   positives  object\n",
            " 1   negatives  object\n",
            " 2   anchors    object\n",
            "dtypes: object(3)\n",
            "memory usage: 136.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6jQr_uTRDEKq"
      },
      "source": [
        "Creating data files to feed into mtg_dataset builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dORkdLWER-pP",
        "outputId": "04b4bbe8-db8d-4059-d4eb-f9a7154e2d81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positives</th>\n",
              "      <th>negatives</th>\n",
              "      <th>anchors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>206</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5957233</th>\n",
              "      <td>176</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5957234</th>\n",
              "      <td>81</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5957235</th>\n",
              "      <td>73</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5957236</th>\n",
              "      <td>176</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5957237</th>\n",
              "      <td>22</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5957238 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        positives                                          negatives  \\\n",
              "0             171  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
              "1              94  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2             207  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3             206  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
              "4             200  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "...           ...                                                ...   \n",
              "5957233       176  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "5957234        81  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "5957235        73  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "5957236       176  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "5957237        22  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                   anchors  \n",
              "0        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "...                                                    ...  \n",
              "5957233  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "5957234  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "5957235  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "5957236  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "5957237  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "\n",
              "[5957238 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[0:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cd3NRQV22RRA"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df, card_dict, pathout):\n",
        "  file_num = 0\n",
        "  file_data = []\n",
        "  for idx, row in df.iterrows():\n",
        "      output = []\n",
        "      positives = row['positives']\n",
        "      #positives_col = row['positives']\n",
        "      #positives = [str(i) for i, val in enumerate(positives_col) if val > 0]\n",
        "    \n",
        "      negatives_col = row['negatives']\n",
        "      negatives = [str(i) for i, val in enumerate(negatives_col) if val > 0 and str(i) not in positives]\n",
        "      #negatives = [str(i) for i, val in enumerate(negatives_col) if val > 0]\n",
        "    \n",
        "      anchors_col = row['anchors']\n",
        "      anchors = []\n",
        "      for i, val in enumerate(anchors_col):\n",
        "          if val > 0:\n",
        "              for j in range(val):\n",
        "                  anchors.append(str(i))\n",
        "      anchors = \",\".join(anchors)\n",
        "    \n",
        "      for neg in negatives:\n",
        "            output.append(f\"{positives};{neg};{anchors}\")\n",
        "      file_data.extend(output)\n",
        "      if len(file_data) >= 997920:\n",
        "                with open(pathout+'train_data'+str(file_num)+'.pt','wb') as w:\n",
        "                    pickle.dump(file_data[:997920],w)\n",
        "                    file_num += 1\n",
        "                    file_data = file_data[997920:]\n",
        "                    w.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "v-hjgTUjSoBz"
      },
      "outputs": [],
      "source": [
        "preprocess_data(df, card_dict, \"training_data/\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uZgiicbnC7eK"
      },
      "source": [
        "Extra Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJQPz7295L_V"
      },
      "outputs": [],
      "source": [
        "#visualizing pack contents\n",
        "row = 0\n",
        "pack_card_cols = df.columns[df.columns.str.startswith('pack_card')]\n",
        "pack = df.loc[row, pack_card_cols][df.loc[row, pack_card_cols] == 1]\n",
        "pack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRNq8JXLFvcn"
      },
      "outputs": [],
      "source": [
        "#creating anchor, positive and negative tensor columns\n",
        "anchor_cols = df.columns[df.columns.str.startswith('pool_')]\n",
        "df['anchors'] = df[anchor_cols].apply(lambda x: torch.tensor(x.values.tolist()), axis=1)\n",
        "pack_cols = df.columns[df.columns.str.startswith('pack_card')]\n",
        "df['positives'] = df.apply(lambda row: torch.tensor([int(row[col] if row['pick'] in col else 0) for col in pack_cols]), axis=1)\n",
        "df[\"negatives\"] = df[pack_cols].apply(lambda x: torch.tensor(x.values.tolist()), axis=1)\n",
        "df[\"negatives\"] = df[\"negatives\"] - df[\"positives\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgwDosOwC5Ud"
      },
      "outputs": [],
      "source": [
        "# API request form taken from Ryan Saxe\n",
        "def get_card_rating_data(expansion, endpoint=None, start=\"2022-09-01\", end=\"2023-05-24\", colors=None):\n",
        "    if endpoint is None:\n",
        "        endpoint = f\"https://www.17lands.com/card_ratings/data?expansion={expansion.upper()}&format=PremierDraft\"\n",
        "        if start is not None:\n",
        "            endpoint += f\"&start_date={start}\"\n",
        "        if end is not None:\n",
        "            endpoint += f\"&end_date={end}\"\n",
        "        if colors is not None:\n",
        "            endpoint += f\"&colors={colors}\"\n",
        "    card_json = requests.get(endpoint).json()\n",
        "    card_df = pd.DataFrame(card_json).fillna(0.0)\n",
        "    #numerical_cols = card_df.columns[card_df.dtypes != object]\n",
        "    #card_df[\"name\"] = card_df[\"name\"].str.lower()\n",
        "    card_df = card_df.set_index(\"name\")\n",
        "    return card_df[[\"rarity\", \"color\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAQRnm0T1xVl"
      },
      "outputs": [],
      "source": [
        "def replace_colors(match):\n",
        "    color_mapping = {'G': 'Green', 'R': 'Red', 'B': 'Black', 'U': 'Blue', 'W': 'White'}\n",
        "    colors = match.group(0)\n",
        "    replacements = [color_mapping.get(color, color) for color in colors]\n",
        "    return ', '.join(replacements)\n",
        "\n",
        "def add_stats(rate_df, stats_df):\n",
        "# adding basic lands\n",
        "  basic_lands = pd.DataFrame({\n",
        "    'rarity': ['C', 'C', 'C', 'C', 'C'],\n",
        "    'color': ['', '', '', '', '']}, \n",
        "    index=['Plains', 'Island', 'Swamp', 'Mountain', 'Forest'])\n",
        "\n",
        "  stats_df = pd.concat([stats_df, basic_lands])\n",
        "\n",
        "# renaming rarities\n",
        "  rarities = {'uncommon': 'U', 'rare': 'R', 'common': 'C', 'mythic': 'M', 'basic':'C'}\n",
        "  stats_df[\"rarity\"] = stats_df['rarity'].replace(rarities)\n",
        "\n",
        "# apply color replacement\n",
        "  stats_df['color'] = stats_df['color'].str.replace(r'[GWRBU]+', replace_colors, regex=True)\n",
        "  stats_df['color'] = stats_df['color'].replace('', 'Colourless')\n",
        "\n",
        "# final concat\n",
        "  final_df = pd.concat([rate_df, stats_df], axis=1)\n",
        "  return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdpTrm_DgsI6"
      },
      "outputs": [],
      "source": [
        "# Creating the pick rate file\n",
        "\n",
        "def get_pickrate(df, path):\n",
        "# Step 1: Count the number of times each card was picked\n",
        "  pick_counts = df['pick'].value_counts().sort_index()\n",
        "\n",
        "# Step 2: Count the number of times each card was possible to be picked\n",
        "  pack_cols = df.columns[df.columns.str.startswith('pack_card_')]\n",
        "  possible_counts = df[pack_cols].sum()\n",
        "  possible_counts.index = possible_counts.index.str.replace('pack_card_', '')\n",
        "\n",
        "# Step 3: Calculate the pick rate\n",
        "  pick_rate = pick_counts / possible_counts\n",
        "\n",
        "# Step 4: Create pickrate file\n",
        "  rate_df = pd.concat([pick_rate.rename('pick_rate'), pick_counts.rename('pick_count')], axis=1)\n",
        "  rate_df['pick_rate'] = rate_df['pick_rate'].fillna(0)\n",
        "  rate_df['pick_count'] = rate_df['pick_count'].fillna(0)\n",
        "\n",
        "# Step 5: Get rarity and color for graphics/tables\n",
        "  stats_df = get_card_rating_data(\"DMU\")\n",
        "  final_df = add_stats(rate_df, stats_df)\n",
        "\n",
        "# Step 6: Save to csv\n",
        "  final_df.to_csv(path, index=True, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja-s_a6UC7un"
      },
      "outputs": [],
      "source": [
        "def compute_pick_chance(dataset):\n",
        "  df = load_data(dataset)\n",
        "  other_cols = np.array(df.columns[0:3])\n",
        "  sorted_cols = np.sort(df.columns[3:].tolist())\n",
        "  sorted_cols = np.insert(sorted_cols, 0, other_cols, axis=0)\n",
        "  df = df.loc[:, sorted_cols]\n",
        "  get_pickrate(df, '/content/drive/MyDrive/Colab Notebooks/data/pickratefull.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHTg11Vg75VH"
      },
      "outputs": [],
      "source": [
        "# Create first pick rate file\n",
        "\n",
        "def compute_firstpick_chance(dataset):\n",
        "  df = load_data(dataset)\n",
        "  other_cols = np.array(df.columns[0:3])\n",
        "  sorted_cols = np.sort(df.columns[3:].tolist())\n",
        "  sorted_cols = np.insert(sorted_cols, 0, other_cols, axis=0)\n",
        "  df = df.loc[:, sorted_cols]\n",
        "  df[\"pick_number\"] = df[\"pick_number\"].astype(\"int8\")\n",
        "\n",
        "# Step 1: Filter df to only get first picks (pack_number AND pick_number are both 0)\n",
        "  filtered_df = df[(df['pack_number'] == 0) & (df['pick_number'] == 0)]\n",
        "# Step 2: Get first pick rates\n",
        "  get_pickrate(filtered_df, '/content/drive/MyDrive/Colab Notebooks/data/firstpickrate.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy114vAIivIt"
      },
      "outputs": [],
      "source": [
        "compute_pick_chance('/content/drive/MyDrive/Colab Notebooks/data/draft_data_public.DMU.PremierDraft.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qSU9UTyja1W"
      },
      "outputs": [],
      "source": [
        "compute_firstpick_chance('/content/drive/MyDrive/Colab Notebooks/data/draft_data_public.DMU.PremierDraft.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
